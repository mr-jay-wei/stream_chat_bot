# rag/memory_manager.py

import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import json

from . import config


@dataclass
class ConversationTurn:
    """å•è½®å¯¹è¯è®°å½•"""
    question: str
    answer: str
    timestamp: float
    metadata: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        if self.metadata is None:
            self.metadata = {}
        
        # è®¡ç®—å­—ç¬¦é•¿åº¦
        self.char_length = len(self.question) + len(self.answer)
        
        # æˆªæ–­è¿‡é•¿çš„å†…å®¹
        if self.char_length > config.SINGLE_CONVERSATION_MAX_LENGTH:
            max_q_len = config.SINGLE_CONVERSATION_MAX_LENGTH // 2
            max_a_len = config.SINGLE_CONVERSATION_MAX_LENGTH - max_q_len
            
            if len(self.question) > max_q_len:
                self.question = self.question[:max_q_len-3] + "..."
            
            if len(self.answer) > max_a_len:
                self.answer = self.answer[:max_a_len-3] + "..."
            
            # é‡æ–°è®¡ç®—é•¿åº¦
            self.char_length = len(self.question) + len(self.answer)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ConversationTurn':
        """ä»å­—å…¸åˆ›å»ºå¯¹è±¡"""
        return cls(**data)
    
    def get_formatted_time(self) -> str:
        """è·å–æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²"""
        return datetime.fromtimestamp(self.timestamp).strftime("%Y-%m-%d %H:%M:%S")


class ShortTermMemoryManager:
    """çŸ­æœŸè®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨"""
        self.conversations: List[ConversationTurn] = []
        self.total_char_length = 0
        self.max_length = config.SHORT_TERM_MEMORY_MAX_LENGTH
        self.min_rounds = config.MIN_CONVERSATION_ROUNDS
        self.cleanup_strategy = config.MEMORY_CLEANUP_STRATEGY
        self.sliding_window_size = config.SLIDING_WINDOW_SIZE
        
        print(f"çŸ­æœŸè®°å¿†ç®¡ç†å™¨å·²åˆå§‹åŒ– (æœ€å¤§é•¿åº¦: {self.max_length:,} å­—ç¬¦)")
    
    def add_conversation(self, question: str, answer: str, metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        æ·»åŠ ä¸€è½®å¯¹è¯åˆ°è®°å¿†ä¸­
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            answer: AIå›ç­”
            metadata: é¢å¤–çš„å…ƒæ•°æ®
        """
        if not config.ENABLE_SHORT_TERM_MEMORY:
            return
        
        # åˆ›å»ºå¯¹è¯è®°å½•
        conversation = ConversationTurn(
            question=question,
            answer=answer,
            timestamp=time.time(),
            metadata=metadata or {}
        )
        
        # æ·»åŠ åˆ°åˆ—è¡¨
        self.conversations.append(conversation)
        self.total_char_length += conversation.char_length
        
        print(f"ğŸ“ æ·»åŠ å¯¹è¯è®°å½• (é•¿åº¦: {conversation.char_length} å­—ç¬¦, æ€»é•¿åº¦: {self.total_char_length:,} å­—ç¬¦)")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
        self._cleanup_if_needed()
    
    def _cleanup_if_needed(self) -> None:
        """æ ¹æ®ç­–ç•¥æ¸…ç†è®°å¿†"""
        if self.total_char_length <= self.max_length:
            return
        
        if self.cleanup_strategy == "auto":
            self._auto_cleanup()
        elif self.cleanup_strategy == "sliding_window":
            self._sliding_window_cleanup()
        # manualç­–ç•¥ä¸è‡ªåŠ¨æ¸…ç†
    
    def _auto_cleanup(self) -> None:
        """
        è‡ªåŠ¨æ¸…ç†ç­–ç•¥ï¼šä¸¥æ ¼æ§åˆ¶æ€»é•¿åº¦ä¸è¶…è¿‡max_length
        ä¼˜å…ˆçº§ï¼šé•¿åº¦é™åˆ¶ > è½®æ•°ä¿ç•™
        å¦‚æœå•è½®å¯¹è¯è¶…é•¿ï¼Œä¼šæˆªå–è¯¥è½®å¯¹è¯çš„å†…å®¹
        """
        removed_count = 0
        truncated_count = 0
        
        # ç¬¬ä¸€é˜¶æ®µï¼šç§»é™¤æ•´è½®å¯¹è¯ç›´åˆ°æ»¡è¶³é•¿åº¦è¦æ±‚æˆ–åªå‰©ä¸€è½®
        while (self.total_char_length > self.max_length and len(self.conversations) > 1):
            removed_conversation = self.conversations.pop(0)
            self.total_char_length -= removed_conversation.char_length
            removed_count += 1
        
        # ç¬¬äºŒé˜¶æ®µï¼šå¦‚æœè¿˜æ˜¯è¶…é•¿ä¸”åªå‰©ä¸€è½®å¯¹è¯ï¼Œæˆªå–è¯¥è½®å¯¹è¯
        if self.total_char_length > self.max_length and len(self.conversations) == 1:
            last_conversation = self.conversations[0]
            
            # è®¡ç®—éœ€è¦æˆªå–å¤šå°‘å­—ç¬¦
            excess_chars = self.total_char_length - self.max_length
            target_length = last_conversation.char_length - excess_chars
            
            if target_length > 0:
                # æŒ‰æ¯”ä¾‹æˆªå–é—®é¢˜å’Œç­”æ¡ˆ
                total_original_length = len(last_conversation.question) + len(last_conversation.answer)
                question_ratio = len(last_conversation.question) / total_original_length
                answer_ratio = len(last_conversation.answer) / total_original_length
                
                target_question_length = int(target_length * question_ratio)
                target_answer_length = target_length - target_question_length
                
                # æˆªå–é—®é¢˜å’Œç­”æ¡ˆ
                if target_question_length > 3:  # ä¿ç•™è‡³å°‘3ä¸ªå­—ç¬¦ç”¨äº"..."
                    truncated_question = last_conversation.question[:target_question_length-3] + "..."
                else:
                    truncated_question = "..."
                
                if target_answer_length > 3:  # ä¿ç•™è‡³å°‘3ä¸ªå­—ç¬¦ç”¨äº"..."
                    truncated_answer = last_conversation.answer[:target_answer_length-3] + "..."
                else:
                    truncated_answer = "..."
                
                # æ›´æ–°å¯¹è¯å†…å®¹
                old_length = last_conversation.char_length
                last_conversation.question = truncated_question
                last_conversation.answer = truncated_answer
                last_conversation.char_length = len(truncated_question) + len(truncated_answer)
                
                # æ›´æ–°æ€»é•¿åº¦
                self.total_char_length = self.total_char_length - old_length + last_conversation.char_length
                truncated_count = 1
                
                print(f"âš ï¸  æœ€åä¸€è½®å¯¹è¯è¿‡é•¿ï¼Œå·²æˆªå– {old_length - last_conversation.char_length} å­—ç¬¦")
            else:
                # å¦‚æœç›®æ ‡é•¿åº¦å¤ªå°ï¼Œç›´æ¥æ¸…ç©ºè¯¥è½®å¯¹è¯
                self.conversations.clear()
                self.total_char_length = 0
                removed_count += 1
                print(f"âš ï¸  å•è½®å¯¹è¯è¶…å‡ºé™åˆ¶å¤ªå¤šï¼Œå·²æ¸…ç©ºæ‰€æœ‰è®°å¿†")
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šå¦‚æœè¿˜æœ‰å¤šè½®å¯¹è¯ä½†ä»è¶…é•¿ï¼Œç»§ç»­ç§»é™¤ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
        while self.total_char_length > self.max_length and len(self.conversations) > 0:
            removed_conversation = self.conversations.pop(0)
            self.total_char_length -= removed_conversation.char_length
            removed_count += 1
        
        # è¾“å‡ºæ¸…ç†ç»“æœ
        if removed_count > 0 or truncated_count > 0:
            messages = []
            if removed_count > 0:
                messages.append(f"ç§»é™¤äº† {removed_count} è½®æ—§å¯¹è¯")
            if truncated_count > 0:
                messages.append(f"æˆªå–äº† {truncated_count} è½®å¯¹è¯å†…å®¹")
            
            print(f"ğŸ§¹ è‡ªåŠ¨æ¸…ç†å®Œæˆï¼š{', '.join(messages)} (å½“å‰æ€»é•¿åº¦: {self.total_char_length:,} å­—ç¬¦)")
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ç»å¯¹ä¸è¶…è¿‡é™åˆ¶
        if self.total_char_length > self.max_length:
            print(f"âŒ è­¦å‘Šï¼šæ¸…ç†åä»è¶…å‡ºé™åˆ¶ ({self.total_char_length:,} > {self.max_length:,})")
            # ç´§æ€¥å¤„ç†ï¼šç›´æ¥æ¸…ç©º
            self.conversations.clear()
            self.total_char_length = 0
            print(f"ğŸš¨ ç´§æ€¥æ¸…ç©ºæ‰€æœ‰è®°å¿†ä»¥é¿å…è¶…å‡ºé™åˆ¶")
    
    def _sliding_window_cleanup(self) -> None:
        """æ»‘åŠ¨çª—å£æ¸…ç†ç­–ç•¥ï¼šä¿æŒå›ºå®šæ•°é‡çš„å¯¹è¯"""
        if len(self.conversations) <= self.sliding_window_size:
            return
        
        # è®¡ç®—éœ€è¦ç§»é™¤çš„å¯¹è¯æ•°é‡
        excess_count = len(self.conversations) - self.sliding_window_size
        
        # ç§»é™¤æœ€æ—§çš„å¯¹è¯
        for _ in range(excess_count):
            removed_conversation = self.conversations.pop(0)
            self.total_char_length -= removed_conversation.char_length
        
        print(f"ğŸªŸ æ»‘åŠ¨çª—å£æ¸…ç†äº† {excess_count} è½®æ—§å¯¹è¯ (ä¿ç•™æœ€è¿‘ {self.sliding_window_size} è½®)")
    
    def get_recent_conversations(self, count: Optional[int] = None) -> List[ConversationTurn]:
        """
        è·å–æœ€è¿‘çš„å¯¹è¯è®°å½•
        
        Args:
            count: è·å–çš„å¯¹è¯è½®æ•°ï¼ŒNoneè¡¨ç¤ºè·å–æ‰€æœ‰
            
        Returns:
            å¯¹è¯è®°å½•åˆ—è¡¨
        """
        if count is None:
            return self.conversations.copy()
        
        return self.conversations[-count:] if count > 0 else []
    
    def get_conversation_context(self, include_count: Optional[int] = None) -> str:
        """
        è·å–å¯¹è¯ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œç”¨äºæä¾›ç»™LLM
        
        Args:
            include_count: åŒ…å«çš„å¯¹è¯è½®æ•°ï¼ŒNoneè¡¨ç¤ºåŒ…å«æ‰€æœ‰
            
        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯ä¸Šä¸‹æ–‡
        """
        conversations = self.get_recent_conversations(include_count)
        
        if not conversations:
            return ""
        
        context_parts = []
        for i, conv in enumerate(conversations, 1):
            context_parts.append(f"ç¬¬{i}è½®å¯¹è¯:")
            context_parts.append(f"ç”¨æˆ·: {conv.question}")
            context_parts.append(f"åŠ©æ‰‹: {conv.answer}")
            context_parts.append("")  # ç©ºè¡Œåˆ†éš”
        
        return "\n".join(context_parts).strip()
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """
        è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.conversations:
            return {
                "total_conversations": 0,
                "total_char_length": 0,
                "memory_usage_percent": 0.0,
                "oldest_conversation": None,
                "newest_conversation": None,
                "average_conversation_length": 0
            }
        
        return {
            "total_conversations": len(self.conversations),
            "total_char_length": self.total_char_length,
            "memory_usage_percent": (self.total_char_length / self.max_length) * 100,
            "oldest_conversation": self.conversations[0].get_formatted_time(),
            "newest_conversation": self.conversations[-1].get_formatted_time(),
            "average_conversation_length": self.total_char_length // len(self.conversations)
        }
    
    def clear_memory(self) -> int:
        """
        æ¸…ç©ºæ‰€æœ‰è®°å¿†
        
        Returns:
            æ¸…é™¤çš„å¯¹è¯è½®æ•°
        """
        cleared_count = len(self.conversations)
        self.conversations.clear()
        self.total_char_length = 0
        
        print(f"ğŸ—‘ï¸ å·²æ¸…ç©ºæ‰€æœ‰è®°å¿† (æ¸…é™¤äº† {cleared_count} è½®å¯¹è¯)")
        return cleared_count
    
    def remove_old_conversations(self, keep_count: int) -> int:
        """
        æ‰‹åŠ¨ç§»é™¤æ—§å¯¹è¯ï¼Œä¿ç•™æŒ‡å®šæ•°é‡çš„æœ€æ–°å¯¹è¯
        
        Args:
            keep_count: ä¿ç•™çš„å¯¹è¯è½®æ•°
            
        Returns:
            ç§»é™¤çš„å¯¹è¯è½®æ•°
        """
        if keep_count >= len(self.conversations):
            return 0
        
        # è®¡ç®—éœ€è¦ç§»é™¤çš„æ•°é‡
        remove_count = len(self.conversations) - keep_count
        
        # ç§»é™¤æœ€æ—§çš„å¯¹è¯
        removed_conversations = self.conversations[:remove_count]
        self.conversations = self.conversations[remove_count:]
        
        # æ›´æ–°æ€»é•¿åº¦
        removed_length = sum(conv.char_length for conv in removed_conversations)
        self.total_char_length -= removed_length
        
        print(f"ğŸ§¹ æ‰‹åŠ¨ç§»é™¤äº† {remove_count} è½®æ—§å¯¹è¯ (å½“å‰æ€»é•¿åº¦: {self.total_char_length:,} å­—ç¬¦)")
        return remove_count
    
    def search_conversations(self, keyword: str, limit: int = 10) -> List[Tuple[int, ConversationTurn]]:
        """
        åœ¨å¯¹è¯å†å²ä¸­æœç´¢å…³é”®è¯
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            åŒ¹é…çš„å¯¹è¯è®°å½•åˆ—è¡¨ï¼ŒåŒ…å«ç´¢å¼•å’Œå¯¹è¯å¯¹è±¡
        """
        results = []
        keyword_lower = keyword.lower()
        
        for i, conv in enumerate(self.conversations):
            if (keyword_lower in conv.question.lower() or 
                keyword_lower in conv.answer.lower()):
                results.append((i, conv))
                
                if len(results) >= limit:
                    break
        
        return results
    
    def export_conversations(self, file_path: str) -> bool:
        """
        å¯¼å‡ºå¯¹è¯è®°å½•åˆ°JSONæ–‡ä»¶
        
        Args:
            file_path: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¯¼å‡ºæ˜¯å¦æˆåŠŸ
        """
        try:
            export_data = {
                "export_time": datetime.now().isoformat(),
                "total_conversations": len(self.conversations),
                "total_char_length": self.total_char_length,
                "conversations": [conv.to_dict() for conv in self.conversations]
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“¤ å¯¹è¯è®°å½•å·²å¯¼å‡ºåˆ°: {file_path}")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¯¹è¯è®°å½•å¤±è´¥: {e}")
            return False
    
    def import_conversations(self, file_path: str, append: bool = False) -> bool:
        """
        ä»JSONæ–‡ä»¶å¯¼å…¥å¯¹è¯è®°å½•
        
        Args:
            file_path: å¯¼å…¥æ–‡ä»¶è·¯å¾„
            append: æ˜¯å¦è¿½åŠ åˆ°ç°æœ‰è®°å½•ï¼ˆFalseè¡¨ç¤ºæ›¿æ¢ï¼‰
            
        Returns:
            å¯¼å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                import_data = json.load(f)
            
            imported_conversations = [
                ConversationTurn.from_dict(conv_data) 
                for conv_data in import_data['conversations']
            ]
            
            if not append:
                self.clear_memory()
            
            # æ·»åŠ å¯¼å…¥çš„å¯¹è¯
            for conv in imported_conversations:
                self.conversations.append(conv)
                self.total_char_length += conv.char_length
            
            # æ¸…ç†å¦‚æœéœ€è¦
            self._cleanup_if_needed()
            
            print(f"ğŸ“¥ å·²å¯¼å…¥ {len(imported_conversations)} è½®å¯¹è¯è®°å½•")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å…¥å¯¹è¯è®°å½•å¤±è´¥: {e}")
            return False


# åˆ›å»ºå…¨å±€è®°å¿†ç®¡ç†å™¨å®ä¾‹
memory_manager = ShortTermMemoryManager()